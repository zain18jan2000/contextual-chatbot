{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe90751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 11:12:26.174429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 11:12:31.905211: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-22 11:12:31.905247: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-22 11:12:32.425781: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 11:12:45.681184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-22 11:12:45.681420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-22 11:12:45.681433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import random\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from datetime import datetime, date\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "277d6f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi',\n",
       "    'Hey',\n",
       "    'How are you',\n",
       "    'Is anyone there?',\n",
       "    'Hello',\n",
       "    'Good day'],\n",
       "   'responses': ['Hi!',\n",
       "    'Hello, thanks for visiting',\n",
       "    'Hi there, Nice to meet you',\n",
       "    'Hi there, ']},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later, thanks for visiting',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
       "  {'tag': 'services',\n",
       "   'patterns': ['Which are your services?',\n",
       "    'How can you help me ?',\n",
       "    'You tell me that',\n",
       "    'Do you provide chat support services?',\n",
       "    'What do you sell?',\n",
       "    'I want to know what are the services you are providing ?',\n",
       "    'I want to know what kind of services you are provide ?',\n",
       "    'I am searching for chatbot',\n",
       "    'I am looking for live chat support services',\n",
       "    'I am in search of chat support service',\n",
       "    'I am after chat support services. Can you help me in this regard ?'],\n",
       "   'responses': ['We are a software house and provide services of live chat support. Are you looking for it? If yes, please share the details of your requirements. ',\n",
       "    'We offer live chart support services. If you are looking for it then you are at the right place. Please share your requirements. ']},\n",
       "  {'tag': 'payments',\n",
       "   'patterns': ['Do you take credit cards?',\n",
       "    'Do you accept Mastercard?',\n",
       "    'Can I pay with Paypal?',\n",
       "    'Are you cash only?'],\n",
       "   'responses': ['We accept VISA, Mastercard and Paypal',\n",
       "    'We accept most major credit cards, and Paypal']},\n",
       "  {'tag': 'delivery',\n",
       "   'patterns': ['How long does delivery take?',\n",
       "    'How long does shipping take?',\n",
       "    'When do I get my delivery?'],\n",
       "   'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']},\n",
       "  {'tag': 'funny',\n",
       "   'patterns': ['Tell me a joke!',\n",
       "    'Tell me something funny!',\n",
       "    'Do you know a joke?'],\n",
       "   'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.',\n",
       "    'What did the buffalo say when his son left for college? Bison.']},\n",
       "  {'tag': 'phone',\n",
       "   'patterns': ['My phone number is',\n",
       "    'This is my phone number.',\n",
       "    'my cell phone number',\n",
       "    'yes, my phone number is',\n",
       "    'sure, my phone number is.'],\n",
       "   'responses': ['Thanks for sharing your phone number',\n",
       "    'Thankyou for sharing it']},\n",
       "  {'tag': 'email',\n",
       "   'patterns': ['My email is',\n",
       "    'This is my email address.',\n",
       "    'my email number',\n",
       "    'yes, my email is',\n",
       "    'sure, my email is.'],\n",
       "   'responses': ['Thanks for sharing your email', 'Thankyou for sharing it']},\n",
       "  {'tag': 'negative',\n",
       "   'patterns': ['No',\n",
       "    'Negative',\n",
       "    'I do not want to share my contact information',\n",
       "    'I do not want to share',\n",
       "    'I do not want to share that',\n",
       "    \"Don't ask for that\",\n",
       "    'No please dont ask for it'],\n",
       "   'responses': ['Ok, I understand', 'Ok, I understand your privacy.']},\n",
       "  {'tag': 'affirmative',\n",
       "   'patterns': ['Yes',\n",
       "    'Why not',\n",
       "    'ok',\n",
       "    'well ok',\n",
       "    'Of course',\n",
       "    'Why not ?',\n",
       "    'Fine'],\n",
       "   'responses': [\"That's great! \", 'Great. ']},\n",
       "  {'tag': 'name',\n",
       "   'patterns': ['Hello, my name is',\n",
       "    'Hi my name is',\n",
       "    'Hi there, my name is',\n",
       "    'my name is',\n",
       "    'I am',\n",
       "    'remember my name is',\n",
       "    'you can call me'],\n",
       "   'responses': ['Thanks, for telling that.', 'Great']},\n",
       "  {'tag': 'interrogative',\n",
       "   'patterns': ['Why are you asking for it ?',\n",
       "    'Why are you asking so many questions ?',\n",
       "    'Why I need to tell that?',\n",
       "    'Is it neccessary to share all of these information ?'],\n",
       "   'responses': ['We try to understand our customers and their needs. That is why we ask these questions.',\n",
       "    \"These information will help to identify our customers and their requirements. Do not worry, we won't share your info with anyone.\"]},\n",
       "  {'tag': 'Null',\n",
       "   'patterns': [''],\n",
       "   'responses': [\"Sorry, I can't help with that\",\n",
       "    'Sorry, I did not understand.']}]}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('intents.json','r') as file:\n",
    "    data = json.load(file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ac0d530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1a5d8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['is','am','the','a','an','be','are','were',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4a310647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = []\n",
    "y = []\n",
    "patterns =[]\n",
    "x = []\n",
    "classes = []\n",
    "# getting the classes(tags) output and patterns from 'data'\n",
    "for intent in data['intents']:\n",
    "    classes.append(intent['tag'])\n",
    "    for pattern in intent['patterns']:\n",
    "# applying tokenizer to convert the sentences into a list of words        \n",
    "        tokens = nltk.word_tokenize(pattern)\n",
    "# here .extend() is used instead of append() since we don't want to append lists in words \n",
    "# but its elements i.e words in 'token'\n",
    "# here 'tokens' is a list of words\n",
    "        words.extend(tokens)\n",
    "        patterns.append(pattern)\n",
    "        y.append(intent['tag'])\n",
    "\n",
    "# converting to lower case, applyging lemmatization removing the puctuations\n",
    "# here 'words' is our vocabulary containing all the words \n",
    "words = [stemmer.stem(word.lower()) for word  in words if word not in string.punctuation and \n",
    "        word not in stop_words]\n",
    "# converting the list to set to avoid doubling of words in in 'words'\n",
    "words = sorted(set(words))\n",
    "words = list(words)\n",
    "\n",
    "for list_ in patterns:\n",
    "    list_ = nltk.word_tokenize(list_)\n",
    "    list_ = [stemmer.stem(lis.lower()) for lis in list_ if lis not in string.punctuation and lis not in stop_words]\n",
    "    x.append(list_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9d469952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the one hot encoding on our training data\n",
    "train_x = []\n",
    "train_y = []\n",
    "training = []\n",
    "empty_list = [0]*len(classes)\n",
    "for idx,list_ in enumerate(x):\n",
    "    doc = []\n",
    "    for word in words:\n",
    "        doc.append(1) if word in list_ else doc.append(0)\n",
    "    output = list(empty_list)\n",
    "    output[classes.index(y[idx])] = 1\n",
    "    training.append([doc,output])\n",
    "random.shuffle(training)       \n",
    "training = np.array(training,dtype = object)\n",
    "train_x = list(training[:,0])\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(list(training[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "815983cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACY_THRESHOLD = 0.99\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):   \n",
    "            print(\"\\nTraining stopped at epoch number:\",epoch)   \n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "473f70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6390 - accuracy: 0.0429\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3388 - accuracy: 0.3000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1305 - accuracy: 0.3714\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9351 - accuracy: 0.4000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6843 - accuracy: 0.4714\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4103 - accuracy: 0.6857\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2291 - accuracy: 0.6714\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1050 - accuracy: 0.7714\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8836 - accuracy: 0.7714\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7583 - accuracy: 0.8286\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.8857\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.9000\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.9000\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.9000\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.9571\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.9286\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.9571\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.9143\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1737 - accuracy: 0.9429\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9429\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9857\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.9857\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9714\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9857\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9571\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9429\n",
      "Epoch 27/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000\n",
      "Training stopped at epoch number: 26\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd492893e80>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (len(train_x[1]),)\n",
    "output_shape = len(train_y[0])      \n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(output_shape, activation = \"softmax\"))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x=train_x, y=train_y, epochs=200, verbose=1,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7b8ac102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0fd1c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying bag of words techniques to convert user's text in binary\n",
    "def bagofwords(msg):\n",
    "    tokens = nltk.word_tokenize(msg)\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokens if token not in string.punctuation and token \n",
    "              not in stop_words]\n",
    "    binary_msg = []\n",
    "    for word in words:\n",
    "        binary_msg.append(1) if word in tokens else binary_msg.append(0)\n",
    "    return np.array(binary_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ed4d1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'phone_dic': ['Thankyou, May I have your phone number ?','Thanks, Can I have your phone number ?'],\n",
    "    'email_dic': ['Can you share your email address ?','May I ask your email adress ?'],\n",
    "    'help_dic': ['how can I help you ?'],\n",
    "    'negative_dic': ['Ok I respect your privacy. ', \"That's ok I respect your privacy.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0a869fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(msg,tag):\n",
    "    boleans = [False, False]\n",
    "\n",
    "    message = bagofwords(msg)\n",
    "    result = model.predict(np.array([message]))\n",
    "    result = np.argmax(result,axis=1)\n",
    "    class_index = list(result)[0] \n",
    "    current_tag = classes[class_index]\n",
    "    if tag == 'greeting_dic':\n",
    "        if current_tag == 'negative':            \n",
    "            response1 = random.choice(dic['negative_dic'])\n",
    "            response2 = random.choice(dic['help_dic'])\n",
    "            response = response1+response2\n",
    "            boleans = [True,True]\n",
    "        elif current_tag == 'name' or current_tag == 'greeting' or current_tag == 'Null' or current_tag == 'affirmative':\n",
    "            response = random.choice(dic['phone_dic'])\n",
    "            boleans = [True,True]\n",
    "            if msg == \"\":\n",
    "                boleans[0] = False\n",
    "             \n",
    "            \n",
    "          \n",
    "    if tag == 'name' or tag == 'affirmative' or tag == 'Null':\n",
    "        if boleans[1] == False:\n",
    "            if current_tag == 'negative':\n",
    "                response1 = random.choice(dic['negative_dic'])\n",
    "                response2 = random.choice(dic['email_dic'])\n",
    "                response = response1+' '+response2\n",
    "                boleans = [True,True]\n",
    "                \n",
    "            elif current_tag == 'phone' or current_tag == 'affirmative' or current_tag == 'Null':\n",
    "                response = 'Thanks, '+ random.choice(dic['email_dic'])\n",
    "                boleans = [True,True]\n",
    "                if current_tag == 'affirmative' or current_tag == 'Null':\n",
    "                    if msg[-1].isnumeric():\n",
    "                        current_tag = 'phone'\n",
    "                        \n",
    "                \n",
    "    if tag == 'phone' or tag == 'affirmative' or tag == 'negative':\n",
    "        if current_tag == 'negative':\n",
    "            response1 = random.choice(dic['negative_dic'])\n",
    "            response2 = random.choice(dic['help_dic'])\n",
    "            response = response1 +\" \"+ response2\n",
    "            boleans = [True,True]\n",
    "        elif current_tag == 'affirmative' or current_tag == 'email' or current_tag == 'Null':\n",
    "            \n",
    "            response1 = 'Thanks, '\n",
    "            response2 = random.choice(dic['help_dic'])\n",
    "            response = response1+response2\n",
    "            boleans = [True,True]\n",
    "            if \".com\" not in msg:\n",
    "                print('yes')\n",
    "                boleans[0] = False\n",
    "            else:\n",
    "                current_tag = 'email'\n",
    "                \n",
    "    # user se phone number pucha usne mana krdia. ab email pucho\n",
    "    if tag == 'negative':\n",
    "        if current_tag == 'negative':\n",
    "            response1 = random.choice(dic['negative_dic'])\n",
    "            response2 = random.choice(dic['help_dic'])\n",
    "            response = response1+response2\n",
    "            bolean = True\n",
    "        elif current_tag == 'affirmative' or current_tag == 'email':\n",
    "            response1 = 'Thankyou, '\n",
    "            response2 = random.choice(dic['help_dic'])\n",
    "            response = response1+response2\n",
    "            bolean = True\n",
    "        \n",
    "            \n",
    "            \n",
    "    for intent in data['intents']:\n",
    "        if intent['tag'] == current_tag:\n",
    "            \n",
    "            \n",
    "            if boleans[0] == False:\n",
    "                response = random.choice(intent['responses'])\n",
    "            return response,current_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "99d2b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am chatbot. May I ask your name\n",
      "i am zain\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Thanks, Can I have your phone number ? --> name\n",
      "of course, it is +923232612434\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Thanks, Can you share your email address ? --> phone\n",
      "zain.18j20000@gmail.com\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Thanks, how can I help you ? --> email\n",
      "you tell me how can you help me\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "We are a software house and provide services of live chat support. Are you looking for it? If yes, please share the details of your requirements.  --> services\n",
      "that's great\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "My pleasure --> thanks\n",
      "i am looking for chatbot for my website \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "We are a software house and provide services of live chat support. Are you looking for it? If yes, please share the details of your requirements.  --> services\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [217], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-->\u001b[39m\u001b[38;5;124m'\u001b[39m, tag)\n\u001b[0;32m----> 6\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     response,tag \u001b[38;5;241m=\u001b[39mprediction(text,tag)\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/ipykernel/kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyter/environment/lib/python3.10/site-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print('Hi! I am chatbot. May I ask your name')\n",
    "text = input()\n",
    "response, tag = prediction(text,\"greeting_dic\") \n",
    "while True:\n",
    "    print(response)\n",
    "    text = input()\n",
    "    response,tag =prediction(text,tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a5bfc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "email = \"zain.18j2000@gmail.com\"\n",
    "if '.com' in email:\n",
    "    print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4370359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
